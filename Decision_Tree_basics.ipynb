{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pydotplus\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([u'MemberID', u'InpatientDays', u'ERVisits', u'OfficeVisits',\n",
      "       u'Narcotics', u'DaysSinceLastERVisit', u'Pain', u'TotalVisits',\n",
      "       u'ProviderCount', u'MedicalClaims', u'ClaimLines',\n",
      "       u'StartedOnCombination', u'AcuteDrugGapSmall', u'PoorCare'],\n",
      "      dtype='object')\n",
      "(131, 14)\n"
     ]
    }
   ],
   "source": [
    "#this is the same data that ahs been used for Logistic Regressio Case study. To know more abot the data\n",
    "#refer to the Logistic regression case study\n",
    "df=pd.read_csv(\"quality.csv\")#read the csv into python\n",
    "print df.columns\n",
    "print df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[[\"DaysSinceLastERVisit\",\"Narcotics\"]],df['PoorCare'],test_size=0.3,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "mycols=[\"DaysSinceLastERVisit\",\"Narcotics\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl_tree=tree.DecisionTreeClassifier(criterion=\"gini\",random_state=0,max_depth=12,min_samples_leaf=10)\n",
    "#the below 2 parameters can be used to control for Overfitting. Try to play around with these\n",
    "#and come up with a better model\n",
    "#max_depth=5 --- defines the depth of the tree.. More depth may lead to Overfitting\n",
    "#min_samples_leaf=8--- defines when the splitting will stop. here for example\n",
    "# if a node/BUCKET has less than 8 data pints, it will not go for a further split. This too wil control\n",
    "#overfitting. Smaller thsi value, more the overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl_tree=cl_tree.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "col_0      0  1\n",
      "PoorCare       \n",
      "0         63  4\n",
      "1         15  9\n",
      "0.791208791209\n"
     ]
    }
   ],
   "source": [
    "#lets first predict on the train data\n",
    "pred_train=cl_tree.predict(X_train)\n",
    "#for the confusion matrix\n",
    "print pd.crosstab(y_train,pred_train)\n",
    "# since we gave a very small depth &/or Very large value of min_samples_leaf, the Model is Underfit\n",
    "#it is going for very fewer spilts.... If we see below it is not even predicitng a 1. \n",
    "#Its only predicting 0's.\n",
    "\n",
    "Accuracy_train=72.0/(67+24.0)\n",
    "print Accuracy_train #74%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#download graphviz from here and install on your sustem\n",
    "#https://graphviz.gitlab.io/_pages/Download/Download_windows.html\n",
    "#graphviz-2.38.msi.this has to be downloaded\n",
    "#then go to my computer properties--> advanced system settings--> Environment variables\n",
    "#NEW -->\n",
    "#variable name ---  PATH\n",
    "#variable value  -----   C:\\Program Files (x86)\\Graphviz2.38\\bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.externals.six import StringIO  \n",
    "from IPython.display import Image  \n",
    "from sklearn.tree import export_graphviz\n",
    "import pydotplus#pip install pydotplus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dot_data = StringIO()\n",
    "export_graphviz(cl_tree, out_file=dot_data, feature_names=mycols, \n",
    "                filled=True, rounded=True,\n",
    "                special_characters=True)\n",
    "\n",
    "graph = pydotplus.graph_from_dot_data(dot_data.getvalue()) \n",
    "Image(graph.create_png())\n",
    "graph.write_png('tree_1.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This wouold give you a PNG image in your working directory\n",
    "#Lets understand the tree\n",
    "#First is A variables and a decisio on it\n",
    "#Second is the value of gini index\n",
    "#Third is the # of data points in the sample\n",
    "# Forth is the [# of 0's , # of 1's]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "col_0      0  1\n",
      "PoorCare       \n",
      "0         29  2\n",
      "1          5  4\n",
      "0.775\n"
     ]
    }
   ],
   "source": [
    "#use the tree to make prediction\n",
    "pred=cl_tree.predict(X_test)\n",
    "#for the confusion matrix\n",
    "print pd.crosstab(y_test,pred)\n",
    "Accuracy_test=(31.0)/(31+9.0)\n",
    "print Accuracy_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#so we Got 73% on train & 77% on Test.... Both are comparable. But since no 1's are getting predicted\n",
    "#it means it is a very simple... or underfot model..lets increease the DEPTH and decrease \n",
    "#min_samples_leaf to maek the tree more complex... Look at the Imarges formed to verify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "col_0      0   1\n",
      "PoorCare        \n",
      "0         64   3\n",
      "1         10  14\n",
      "0.857142857143\n",
      "*****************\n",
      "col_0      0  1\n",
      "PoorCare       \n",
      "0         28  3\n",
      "1          5  4\n",
      "0.8\n"
     ]
    }
   ],
   "source": [
    "cl_tree2=tree.DecisionTreeClassifier(criterion=\"gini\",random_state=0,max_depth=12,min_samples_leaf=3)\n",
    "#THIS MEANS IT WILL GO ON SPLITITNG AS LONG AS IT EITHER REACHES A DEPTH OF 12 OR IT HAS LESS THAN\n",
    "#3 POINTS IN THE BUCKET......\n",
    "cl_tree2=cl_tree2.fit(X_train,y_train)\n",
    "#lets first predict on the train data\n",
    "pred_train=cl_tree2.predict(X_train)\n",
    "#for the confusion matrix\n",
    "print pd.crosstab(y_train,pred_train)\n",
    "Accuracy_train=(64.0+14)/(64+14.0+10+3)\n",
    "print Accuracy_train #85.7% better Than before.But we shud make sure performace is good in test as wel\n",
    "print \"*****************\"\n",
    "dot_data = StringIO()\n",
    "export_graphviz(cl_tree2, out_file=dot_data, feature_names=mycols, \n",
    "                filled=True, rounded=True,\n",
    "                special_characters=True)\n",
    "\n",
    "graph = pydotplus.graph_from_dot_data(dot_data.getvalue()) \n",
    "Image(graph.create_png())\n",
    "graph.write_png('tree_2.png')\n",
    "#use the tree to make prediction o test\n",
    "pred2=cl_tree2.predict(X_test)\n",
    "#for the confusion matrix\n",
    "print pd.crosstab(y_test,pred2)\n",
    "Accuracy_test=(28.0+4)/(28+4+5+3.0)\n",
    "print Accuracy_test#80% on test which is quit  #e good..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#So these parameters are good to freeze as the accuracy is consistently higher in bith train & test\n",
    "# Decision tree works weel if # of data points are huge...in 1000's. \n",
    "# this data is preety small and only for illustration purpose...."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
